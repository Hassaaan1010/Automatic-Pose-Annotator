{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source paths\n",
    "rgb_source_path = \"/home/hassaan/Downloads/allFinal/\"\n",
    "dpt_source_path = \"/home/hassaan/Downloads/DPT2/\"\n",
    "\n",
    "# destination paths\n",
    "rgb_destination_path = \"/home/hassaan/Downloads/rgb_split/\"\n",
    "dpt_destination_path = \"/home/hassaan/Downloads/dataset/images/\"\n",
    "text_destination_path = \"/home/hassaan/Downloads/dataset/labels/\"\n",
    "\n",
    "\n",
    "rgb_files_list = os.listdir(rgb_source_path)\n",
    "rgb_files_list.sort(key=lambda x: int(x.split(\".\")[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_model = YOLO(\"models/yolov8m-pose.pt\")\n",
    "object_model = YOLO(\"models/yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "# utils\n",
    "\n",
    "\n",
    "def object_detection(frame, show=False, model=object_model):\n",
    "\n",
    "    results = model(frame)\n",
    "    bboxes = []\n",
    "    confs = []\n",
    "    # Render the results\n",
    "    for result in results:\n",
    "        if result.boxes is not None:\n",
    "            for box in result.boxes:\n",
    "                # label = model.names[int(box.cls[0])]\n",
    "                confidence = box.conf[0]\n",
    "                if int(box.cls[0]) == 0 and confidence > 0.4:\n",
    "                    confs.append(confidence)\n",
    "                    bbox = box.xyxy[0].numpy().astype(int)\n",
    "                    print(bbox)\n",
    "                    bboxes.append(list(bbox))\n",
    "                    x1, y1, x2, y2 = bbox\n",
    "\n",
    "                    # Draw bounding box and label\n",
    "                    # cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    # cv2.putText(\n",
    "                    #     frame,\n",
    "                    #     f\"{box.cls[0]} {confidence:.2f}\",\n",
    "                    #     (x1, y1 - 10),\n",
    "                    #     cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    #     0.5,\n",
    "                    #     (0, 255, 0),\n",
    "                    #     2,\n",
    "                    # )\n",
    "    while show:\n",
    "        cv2.imshow(\"C\", frame)\n",
    "        if cv2.waitKey(10) & 0xFF == ord(\"q\"):\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    return bboxes, confs\n",
    "\n",
    "\n",
    "# return bboxes, confs\n",
    "\n",
    "\n",
    "def check_overlap_for_2(box1, box2):\n",
    "    # bbox is TL and BR corner coordinates\n",
    "    x1, y1, x2, y2 = box1\n",
    "    a1, b1, a2, b2 = box2\n",
    "\n",
    "    box1_corners = [\n",
    "        (x1, y1),  # TL\n",
    "        (x2, y1),  # TR\n",
    "        (x1, y2),  # BL\n",
    "        (x2, y2),  # BR\n",
    "    ]\n",
    "\n",
    "    while False:\n",
    "        corner_overlap_areas = {\n",
    "            \"TL\": ((a2 - x1) * (b2 - y1)),\n",
    "            \"TR\": ((x1 - a1) * (b2 - y2)),\n",
    "            \"BL\": ((a2 - x1) * (y2 - b1)),\n",
    "            \"BR\": ((x2 - a1) * (y2 - b1)),\n",
    "        }\n",
    "\n",
    "    overlapping_corners = 0\n",
    "    single_corener = ()  # returns corner for single corner case with small overlap\n",
    "    for corner in box1_corners:\n",
    "        x, y = corner\n",
    "        # check if x1,y1 is in box2\n",
    "        if (x >= a1 and x <= a2) and (y >= b1 and y <= b2):\n",
    "            overlapping_corners += 1\n",
    "            single_corener = (x, y)\n",
    "\n",
    "    area = 0\n",
    "    if overlapping_corners > 0:\n",
    "        # calculate the coordinates of the overlapping rectangle\n",
    "        x_left = max(x1, a1)\n",
    "        y_top = max(y1, b1)\n",
    "        x_right = min(x2, a2)\n",
    "        y_bottom = min(y2, b2)\n",
    "\n",
    "        # calculate overlap area\n",
    "        overlap_width = x_right - x_left\n",
    "        overlap_height = y_bottom - y_top\n",
    "        area = overlap_width * overlap_height\n",
    "\n",
    "    return overlapping_corners, area\n",
    "\n",
    "\n",
    "# return overlapping_corners, area\n",
    "\n",
    "\n",
    "def split_people_bboxes(depth_frame, rgb_frame, bboxes, confs, index):\n",
    "\n",
    "    # 1 person\n",
    "    if len(bboxes) == 1:\n",
    "        print(\"CASE 1\")\n",
    "        # return depthmap of corresponding image as it is into dataset\n",
    "        return [depth_frame][rgb_frame]\n",
    "\n",
    "    # 2 person\n",
    "    if len(bboxes) == 2:\n",
    "        print(\"CASE 2\")\n",
    "        bbox1, bbox2 = bboxes\n",
    "        overlapping_corners, area = check_overlap_for_2(bbox1, bbox2)\n",
    "\n",
    "        # no overlap\n",
    "        if area == 0:\n",
    "            print(\"CASE 2.1\")\n",
    "            # sort bboxes to organize by TL corner\n",
    "            bboxes.sort(key=lambda x: x[0])\n",
    "            box1, box2 = bboxes\n",
    "            x1, y1, x2, y2 = box1\n",
    "            a1, b1, a2, b2 = box2\n",
    "\n",
    "            # not right, above or below. :. box1 is to the left of box2\n",
    "            if x2 <= a1:\n",
    "                print(\"CASE 2.1.1\")\n",
    "                mid_x = (x2 + a1) // 2\n",
    "\n",
    "                depth_section1 = depth_frame[:mid_x, :]\n",
    "                depth_section2 = depth_frame[mid_x:, :]\n",
    "\n",
    "                rgb_section1 = rgb_frame[:mid_x, :]\n",
    "                rgb_section2 = rgb_frame[mid_x:, :]\n",
    "\n",
    "            # box1 is above or below box2\n",
    "            else:\n",
    "                print(\"CASE 2.1.2\")\n",
    "                if y2 >= b1:  # if above\n",
    "                    print(\"CASE 2.1.2.1\")\n",
    "                    mid_y = (y2 + b1) // 2\n",
    "\n",
    "                elif b2 >= y1:  # if below\n",
    "                    print(\"CASE 2.1.2.2\")\n",
    "                    mid_y = (y1 + b2) // 2\n",
    "\n",
    "                depth_section1 = depth_frame[:, :mid_y]\n",
    "                depth_section2 = depth_frame[:, mid_y:]\n",
    "\n",
    "                rgb_section1 = rgb_frame[:, :mid_y]\n",
    "                rgb_section2 = rgb_frame[:, mid_y:]\n",
    "\n",
    "            return [depth_section1, depth_section2], [rgb_section1, rgb_section2]\n",
    "\n",
    "        # if overlap\n",
    "        elif area > 0:\n",
    "            print(\"CASE 2.2\")\n",
    "            # corner overlap\n",
    "            if overlapping_corners == 1:\n",
    "                print(\"CASE 2.2.1\")\n",
    "                x1, y1, x2, y2 = bboxes[0]\n",
    "                a1, a2, b1, b2 = bboxes[1]\n",
    "                # if overlap area is less than 30% area of bbox2\n",
    "                if area < 0.3 * (a2 - a1) * (b2 - b1) or area < 0.3 * (x2 - x1) * (y2 - y1):\n",
    "                    print(\"CASE 2.2.1.1\")\n",
    "                    bboxes.sort(key=lambda x: x[0])\n",
    "                    box1, box2 = bboxes\n",
    "\n",
    "                    mid_x = (box1[2] + box2[0]) // 2\n",
    "\n",
    "                    depth_section1 = depth_frame[:, :mid_x]\n",
    "                    depth_section2 = depth_frame[:, mid_x:]\n",
    "\n",
    "                    rgb_section1 = rgb_frame[:, :mid_x]\n",
    "                    rgb_section2 = rgb_frame[:, mid_x:]\n",
    "\n",
    "                    return [depth_section1, depth_section2], [\n",
    "                        rgb_section1,\n",
    "                        rgb_section2,\n",
    "                    ]\n",
    "\n",
    "                # if overlap area is more than 30% area of bbox2\n",
    "                else:\n",
    "                    print(\"CASE 2.2.1.2\")\n",
    "                    box1, box2 = bboxes\n",
    "                    # box1 is significantly more recognizable than box2\n",
    "                    crop_bbox1 = depth_frame[y1:y2,x1:x2]\n",
    "                    crop_bbox2 = depth_frame[b1:b2,a1:a2]\n",
    "                    \n",
    "                    # box1 is in front of box2\n",
    "                    avg_bbox1 = np.average(crop_bbox1)\n",
    "                    avg_bbox2 = np.average(crop_bbox1)\n",
    "                    \n",
    "                    print(avg_bbox1, avg_bbox1)\n",
    "                    \n",
    "                    if avg_bbox1 > avg_bbox2 - 20:\n",
    "                        print(\"CASE 2.2.1.2.1\")\n",
    "                        # use only box1 \n",
    "                        depth_section1 = depth_frame[\n",
    "                            box1[0] : box1[2], box1[1] : box1[3]\n",
    "                        ]\n",
    "                        rgb_section1 = rgb_frame[box1[1] : box1[3], box1[0] : box1[2]]\n",
    "\n",
    "                        return [depth_section1],[rgb_section1]\n",
    "                    \n",
    "                    # box2 is in front of box1\n",
    "                    elif avg_bbox2 > avg_bbox1 - 20:\n",
    "                        print(\"CASE 2.2.1.2.2\")\n",
    "                        # use only box1\n",
    "                        depth_section1 = depth_frame[\n",
    "                            box2[1] : box2[3], box2[0] : box2[2]\n",
    "                        ]\n",
    "                        rgb_section1 = rgb_frame[box2[1] : box2[3], box2[0] : box2[2]]\n",
    "\n",
    "                        return [depth_section1],[rgb_section1]\n",
    "\n",
    "                    else:\n",
    "                        print(\"CASE 2.2.1.2.3\")\n",
    "                        # both box are similarly recognizable and have significant overlap\n",
    "                        while False:\n",
    "                            depth_section1 = depth_frame[\n",
    "                                box1[1] : box1[3], box1[0] : box1[2]\n",
    "                            ]\n",
    "                            depth_section2 = depth_frame[\n",
    "                                box2[1] : box2[3], box2[0] : box2[2]\n",
    "                            ]\n",
    "\n",
    "                            rgb_section1 = rgb_frame[box1[1] : box1[3], box1[0] : box1[2]]\n",
    "                            rgb_section2 = rgb_frame[box2[1] : box2[3], box2[0] : box2[2]]\n",
    "\n",
    "                            return [depth_section1, depth_section2], [\n",
    "                                rgb_section1,\n",
    "                                rgb_section2\n",
    "                            ]\n",
    "                        return [],[]\n",
    "            # edge overlap\n",
    "            elif overlapping_corners == 2:\n",
    "                print(\"CASE 2.2.2\")\n",
    "                \n",
    "                if area < 0.3 * (a2 - a1) * (b2 - b1) or area < 0.3 * (x2 - x1) * (y2 - y1):\n",
    "                        pass\n",
    "\n",
    "            # full image overlap\n",
    "            else:\n",
    "                print(\"CASE 2.2.3\")\n",
    "\n",
    "    # 3 person\n",
    "    if len(bboxes) > 2:\n",
    "        print(\"CASE 3\")\n",
    "        pass\n",
    "\n",
    "    if bboxes == []:\n",
    "        print(\"CASE 4\")\n",
    "        # skip image\n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "for file in rgb_files_list:\n",
    "\n",
    "    # define file path of rgb, depth image\n",
    "    rgb_path = rgb_source_path + file  # /home/hassaan/Downloads/allFinal/0.png\n",
    "    depth_path = dpt_source_path + file  # /home/hassaan/Downloads/DPT2/0.png\n",
    "\n",
    "    # read image\n",
    "    rgb_frame = cv2.imread(rgb_path)\n",
    "    depth_frame = cv2.imread(depth_path)\n",
    "\n",
    "    bboxes, confs = object_detection(rgb_frame)\n",
    "\n",
    "    depth_sections, rgb_sections = split_people_bboxes(\n",
    "        depth_frame=depth_frame,\n",
    "        rgb_frame=rgb_frame,\n",
    "        bboxes=bboxes,\n",
    "        confs=confs,\n",
    "        index=index,\n",
    "    )\n",
    "\n",
    "    if len(depth_sections) == len(rgb_sections):\n",
    "        # for each section\n",
    "        for n in range(len(depth_sections)):\n",
    "\n",
    "            # write depth section to dataset/images/\n",
    "            cv2.imwrite(f\"{dpt_destination_path}{index}.png\", depth_sections[n])\n",
    "\n",
    "            # write rgb section to split_rgb/\n",
    "            cv2.imwrite(f\"{rgb_destination_path}{index}.png\", rgb_sections[n])\n",
    "\n",
    "            index += 1\n",
    "\n",
    "    break  # temporary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "\n",
    "for file in rgb_files_list:\n",
    "    \n",
    "    rgb_path = rgb_source_path + file\n",
    "    # /home/hassaan/Downloads/allFinal/0.png\n",
    "    \n",
    "    depth_path = dpt_source_path + file\n",
    "    # /home/hassaan/Downloads/DPT2/0.png\n",
    "    \n",
    "    \n",
    "    # get depth map approved ? should i not just prune the raw dataset of depth maps my self?\n",
    "    # depth_map = cv2.imread(dpt_source_path+file) #assumind all depth maps have descernable human figure\n",
    "    # while True:\n",
    "    #     cv2.imshow(depth_map)\n",
    "\n",
    "    # read image\n",
    "    rgb_frame = cv2.imread(rgb_path)\n",
    "    depth_frame = cv2.imread(depth_path)\n",
    "\n",
    "    bboxes, confs = object_detection(rgb_frame)\n",
    "    \n",
    "    depth_sections, rgb_sections = split_people_bboxes(depth_frame=depth_frame, rgb_frame=rgb_frame, bboxes=bboxes, confs=confs, index = index)\n",
    "    \n",
    "    for section in rgb_sections:\n",
    "        # write section to rgb dataset     \n",
    "        cv2.write(rgb_destination_path)\n",
    "        index+=1\n",
    "        pass\n",
    "\n",
    "    for section in depth_sections:\n",
    "        # list of frames\n",
    "        # increment index per photo\n",
    "        index +=1\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 2 persons, 2 handbags, 3 chairs, 1 potted plant, 1 tv, 1107.0ms\n",
      "Speed: 2.6ms preprocess, 1107.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[177 222 462 631]\n",
      "[435  97 612 535]\n",
      "CASE 2\n",
      "CASE 2.2\n",
      "CASE 2.2.1\n",
      "CASE 2.2.1.1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# test an image\n",
    "file = \"28.png\"\n",
    "index = 0\n",
    "\n",
    "rgb_path = rgb_source_path + file  # /home/hassaan/Downloads/allFinal/0.png\n",
    "depth_path = dpt_source_path + file  # /home/hassaan/Downloads/DPT2/0.png\n",
    "\n",
    "# read image\n",
    "rgb_frame = cv2.imread(rgb_path)\n",
    "depth_frame = cv2.imread(depth_path)\n",
    "\n",
    "bboxes, confs = object_detection(rgb_frame)\n",
    "\n",
    "try:\n",
    "    depth_sections, rgb_sections = split_people_bboxes(\n",
    "        depth_frame=depth_frame,\n",
    "        rgb_frame=rgb_frame,\n",
    "        bboxes=bboxes,\n",
    "        confs=confs,\n",
    "        index=index,\n",
    "    )\n",
    "except Exception:\n",
    "    print(\n",
    "        \"bboxes\",\n",
    "        bboxes,\n",
    "        \"\\nconfs\",\n",
    "        confs,\n",
    "        \"\\nindex\",\n",
    "        index,\n",
    "        \"\\nfunction return\",\n",
    "        split_people_bboxes(\n",
    "            depth_frame=depth_frame,\n",
    "            rgb_frame=rgb_frame,\n",
    "            bboxes=bboxes,\n",
    "            confs=confs,\n",
    "            index=index,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "if len(depth_sections) == len(rgb_sections):\n",
    "    \n",
    "    if len(depth_sections) != 0:\n",
    "        index+=1\n",
    "    else:    \n",
    "        # for each section\n",
    "        for n in range(len(depth_sections)):\n",
    "\n",
    "            # write depth section to dataset/images/\n",
    "            cv2.imwrite(f\"{dpt_destination_path}{index}.png\", depth_sections[n])\n",
    "\n",
    "            # write rgb section to split_rgb/\n",
    "            cv2.imwrite(f\"{rgb_destination_path}{index}.png\", rgb_sections[n])\n",
    "\n",
    "            index += 1\n",
    "\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hassaan/Downlaods/DPT2/28.png'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpt_source_path + file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m [a, b] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m11\u001b[39m, \u001b[38;5;241m12\u001b[39m]\n\u001b[1;32m      2\u001b[0m a, b\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "[a, b] = [10, 11, 12]\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
